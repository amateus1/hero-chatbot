import re
import streamlit as st
import time
from me_chatbot import Me

# ğŸŒ Layout
st.set_page_config(
    page_title="Meet Hernan 'Al' Mateus â€” AI Resume Agent",
    layout="wide"
)

# ğŸ¨ Style
st.markdown("""
    <style>
    .main .block-container {
        max-width: 1000px;
        padding-top: 1.5rem;
        padding-bottom: 2rem;
        margin: auto;
    }
    h1, h2, h3, h4 {
        font-size: 1.2rem !important;
    }
    p, li {
        font-size: 0.95rem !important;
        line-height: 1.6;
    }
    .message-container {
        display: flex;
        justify-content: flex-end;
        align-items: center;
        gap: 0.5rem;
    }
    .user-bubble {
        background-color: #f0f8ff;
        padding: 12px 16px;
        border-radius: 16px;
        font-size: 16px;
        line-height: 1.6;
        max-width: 85%;
        text-align: right;
        word-break: break-word;
    }
    </style>
""", unsafe_allow_html=True)

# ğŸŒ Language options
language_options = {
    "English": {
        "title": "ğŸ¤– Meet 'Al' Mateus â€” AI Career Agent",
        "desc": (
            "ğŸ‘‹ Welcome! Iâ€™m Alâ€™s digital twin â€” part strategist, part engineer, and a little bit of Star Wars geek.  \n\n"
            "Iâ€™ve been trained on his journey as a **Global AI/MLOps Architect**, **LLM Engineering leader**, and **Scrum 2.0 pioneer**. "
            "I can walk you through how he builds multi-agent AI systems, scales MLOps pipelines, or even how heâ€™s shaping the next era of work with **Agentic AI teams managed by Agile Product Management tools**.  \n\n"
            "Curious where to start? Ask me about his certifications, engineering projects, leadership style, or how to create an Agentic workforce that blends humans and AI.  \n\n"
            "And if you just want the fun stuff â€” yes, Iâ€™ll happily tell you about Thai food, Teslas, or why GPT-5 and DeepSeek are basically the Millennium Falcon of LLMs. ğŸš€"
        ),
        "input_placeholder": "Ask something about Al's career...",
        "consult_prompt": "ğŸ’¡ If you'd like a consultation with Al, feel free to share your email below. The chat will continue regardless.",
        "consult_input": "ğŸ“§ Your email (optional)",
        "consult_success": "âœ… Thanks! Al has been notified and will reach out to you soon."        
    },
    "ä¸­æ–‡ (Chinese)": {
        "title": "ğŸ¤– è®¤è¯† 'Al' Mateus â€”â€” AI ç®€å†åŠ©æ‰‹",
        "desc": (
            "ğŸ‘‹ æ¬¢è¿ï¼æˆ‘æ˜¯ Al çš„æ•°å­—åˆ†èº« â€”â€” æ—¢æ˜¯æˆ˜ç•¥å®¶ï¼Œä¹Ÿæ˜¯å·¥ç¨‹å¸ˆï¼Œè¿˜å¸¦ç‚¹æ˜Ÿçƒå¤§æˆ˜æå®¢çš„å‘³é“ã€‚  \n\n"
            "æˆ‘åŸºäºä»–ä½œä¸º **å…¨çƒ AI/MLOps æ¶æ„å¸ˆ**ã€**LLM å·¥ç¨‹é¢†å¯¼è€…** å’Œ **Scrum 2.0 å…ˆè¡Œè€…** çš„èŒä¸šæ—…ç¨‹è€Œè®­ç»ƒã€‚ "
            "æˆ‘å¯ä»¥å‘ä½ å±•ç¤ºä»–å¦‚ä½•æ„å»ºå¤šæ™ºèƒ½ä½“ AI ç³»ç»Ÿã€æ‰©å±• MLOps æµæ°´çº¿ï¼Œç”šè‡³å¦‚ä½•é€šè¿‡ **ç”±æ•æ·äº§å“ç®¡ç†å·¥å…·é©±åŠ¨çš„ Agentic AI å›¢é˜Ÿ** æ¥å¡‘é€ å·¥ä½œçš„ä¸‹ä¸€ä¸ªæ—¶ä»£ã€‚  \n\n"
            "æƒ³çŸ¥é“ä»å“ªé‡Œå¼€å§‹å—ï¼Ÿå¯ä»¥é—®æˆ‘ä»–çš„è®¤è¯ã€å·¥ç¨‹é¡¹ç›®ã€é¢†å¯¼é£æ ¼ï¼Œæˆ–è€…å¦‚ä½•æ‰“é€ ä¸€ä¸ªèåˆäººç±»ä¸ AI çš„ Agentic å›¢é˜Ÿã€‚  \n\n"
            "å½“ç„¶ï¼Œå¦‚æœä½ åªæ˜¯æƒ³èŠè½»æ¾ç‚¹çš„ â€”â€” æˆ‘ä¹Ÿå¯ä»¥åˆ†äº«ä»–å¯¹æ³°å›½ç¾é£Ÿã€ç‰¹æ–¯æ‹‰èµ›é“ä½“éªŒçš„çƒ­çˆ±ï¼Œæˆ–è€…ä¸ºä»€ä¹ˆ DeepSeek å°±åƒ LLM ä¸–ç•Œé‡Œçš„åƒå¹´éš¼å·ã€‚ ğŸš€"
        ),
        "input_placeholder": "è¯·è¾“å…¥ä½ æƒ³äº†è§£ Al çš„å†…å®¹...",
        "consult_prompt": "ğŸ’¡ å¦‚æœæ‚¨å¸Œæœ›ä¸ Al è¿›è¡Œå’¨è¯¢ï¼Œè¯·åœ¨ä¸‹æ–¹ç•™ä¸‹æ‚¨çš„é‚®ç®±ã€‚èŠå¤©å°†ç»§ç»­è¿›è¡Œã€‚",
        "consult_input": "ğŸ“§ æ‚¨çš„é‚®ç®±ï¼ˆå¯é€‰ï¼‰",
        "consult_success": "âœ… æ„Ÿè°¢ï¼Al å·²ç»æ”¶åˆ°é€šçŸ¥ï¼Œå¾ˆå¿«ä¼šä¸æ‚¨è”ç³»ã€‚"
    },
    "EspaÃ±ol": {
        "title": "ğŸ¤– Conoce a 'Al' Mateus â€” Asistente AI",
        "desc": (
            "ğŸ‘‹ Â¡Bienvenido! Soy el gemelo digital de Al â€” parte estratega, parte ingeniero y con un toque de fanÃ¡tico de Star Wars.  \n\n"
            "He sido entrenado en su trayectoria como **Arquitecto Global de AI/MLOps**, **lÃ­der en IngenierÃ­a de LLMs** y **pionero de Scrum 2.0**. "
            "Puedo mostrarte cÃ³mo construye sistemas de IA multi-agente, cÃ³mo escala pipelines de MLOps, o incluso cÃ³mo estÃ¡ dando forma a la prÃ³xima era del trabajo con **equipos Agentic AI gestionados por herramientas de Agile Product Management**.  \n\n"
            "Â¿Con quÃ© quieres empezar? PregÃºntame sobre sus certificaciones, proyectos de ingenierÃ­a, estilo de liderazgo o cÃ³mo crear una fuerza laboral agÃ©ntica que combine humanos y AI.  \n\n"
            "Y si prefieres lo divertido â€” claro, puedo contarte sobre su pasiÃ³n por la comida tailandesa, las carreras con Tesla o por quÃ© GPT-5 and DeepSeek son bÃ¡sicamente el HalcÃ³n Milenario de los LLMs. ğŸš€"
        ),
        "input_placeholder": "Haz una pregunta sobre Al...",
        "consult_prompt": "ğŸ’¡ Si deseas una consulta con Al, puedes dejar tu correo abajo. El chat seguirÃ¡ normalmente.",
        "consult_input": "ğŸ“§ Tu correo electrÃ³nico (opcional)",
        "consult_success": "âœ… Â¡Gracias! Al ha sido notificado y se pondrÃ¡ en contacto contigo pronto."
    }
}
# ğŸŒ Language select
selected_lang = st.selectbox("ğŸŒ Language / è¯­è¨€ / Idioma", list(language_options.keys()))
ui = language_options[selected_lang]

# ğŸ§  Session state
if "lang_prev" not in st.session_state:
    st.session_state.lang_prev = selected_lang
if st.session_state.lang_prev != selected_lang:
    st.session_state.history = []
    st.session_state.lang_prev = selected_lang

if "history" not in st.session_state:
    st.session_state.history = []

if "user_input" not in st.session_state:
    st.session_state.user_input = ""

if "prompt_count" not in st.session_state:
    st.session_state.prompt_count = 0

# >>> START CHANGE 1: add flags for email tracking <<<
if "email" not in st.session_state:
    st.session_state.email = None
if "email_prompt_shown" not in st.session_state:
    st.session_state.email_prompt_shown = False
# >>> END CHANGE 1 <<<

# ğŸ¤– Load bot
me = Me()

# ğŸ§¢ Header
st.markdown(f"## {ui['title']}")
st.markdown(ui["desc"])

# ğŸ’¬ History rendering
for user, bot in st.session_state.history:
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(
            f"""
            <div class="message-container">
                <div class="user-bubble">
                    {user}
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(bot, unsafe_allow_html=True)

# ğŸ§¾ Input box
user_input = st.chat_input(ui["input_placeholder"])

if st.session_state.user_input:
    user_input = st.session_state.user_input
    st.session_state.user_input = ""

if user_input:
    st.session_state.prompt_count += 1
    display_input = user_input

    contact_keywords = ["contact", "reach", "connect", "talk", "email", "get in touch"]

    # ğŸ“§ Capture email typed directly in chat
    email_match = re.search(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", user_input)
    if email_match and not st.session_state.get("email"):
        from me_chatbot import send_email_alert
        user_email = email_match.group(0)
        try:
            send_email_alert(user_email)
            st.success(f"âœ… Thanks! Al has been notified of your email: {user_email}")
            st.session_state.email = user_email
        except Exception as e:
            st.error(f"âŒ Failed to send email: {e}")

    # ---- multilingual transform after weâ€™ve done any email capture ----
    if selected_lang == "ä¸­æ–‡ (Chinese)":
        user_input = f"è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š{user_input}"
    elif selected_lang == "EspaÃ±ol":
        user_input = f"Por favor responde en espaÃ±ol: {user_input}"

    # ---- show email input ONCE if conditions match and we don't have an email yet ----
    should_suggest_email = (
        (st.session_state.prompt_count >= 3 or any(
            kw in display_input.lower() for kw in contact_keywords
        ))
        and not st.session_state.email
        and not st.session_state.get("email_prompt_shown", False)
    )

    if should_suggest_email:
        st.markdown(ui["consult_prompt"])
        st.session_state.email_prompt_shown = True  # âœ… only show once
            

    # âœ… Right-aligned user bubble
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(
            f"""
            <div class="message-container">
                <div class="user-bubble">
                    {display_input}
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )

    # ğŸ§  Generate assistant response
    response = me.chat(user_input, [])

    # ğŸ“¡ Stream assistant response
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        stream_box = st.empty()
        full_response = ""
        for char in response:
            full_response += char
            stream_box.markdown(full_response + "â–Œ")   # âœ… no unsafe_allow_html
            time.sleep(0.01)
        stream_box.markdown(response)  # âœ… final clean render with Markdown

    # ğŸ’¾ Save to history
    st.session_state.history.append((display_input, response))
